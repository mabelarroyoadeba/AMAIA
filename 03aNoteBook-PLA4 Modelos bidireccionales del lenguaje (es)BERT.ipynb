{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.877 · Análisis de sentimientos y textos</p>\n",
    "<p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia \n",
    "y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "# Módulo 4: Implementación del Deep Learning en el Procesamiento del Lenguaje Natural\n",
    "\n",
    "## Scripts de los métodos de modelo de lenguaje explicados en el módulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook ilustraremos la aplicación de un modelo BERT para hacer dos tareas.<br><br>\n",
    "La primera tarea es la que hacen los estudiantes de idiomas, conocida como <i>fill in the blanks</i>. Ante un texto con una palabra borrada, la tarea es predecir la palabra que debería estar. Este ejercicio sirve para evaluar un modelo del lenguaje, puesto que un buen modelo del lenguaje es aquél que permite predecir la palabra más adecuada a un contexto.<br>\n",
    "Este notebook está inspirado en el notebook <a href=\"https://github.com/ramsrigouthamg/BERT_generate_grammar_MCQ_from_news_article/blob/master/bert-english-vocabulary-mcq-questions.ipynb\"><i>bert-english-vocabulary-mcq-questions</i></a>, de ramsrigouthamg<br><br>\n",
    "La segunda tarea consiste en calcular la similitud entre frases que tienen una palabra polisémica. Concretamente, se demostrará que una frase con el nombre de la compañía <i>Apple</i>, está más cerca de una frase sobre <i>IPhones</i> y <i>acciones</i>, que de una frase que habla sobre pasteles de manzana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in the blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar el paquete <i>pytorch-pretrained-bert</i> y cargarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "installing -> conda install nb_conda\n",
    "installing -> conda update conda\n",
    "installing conda install mkl=2018\n",
    "pip install pytorch-pretrained-bert==0.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer,BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar el tokenizador BERT pre-entrenado y el paquete especializado en predecir una palabra ocultada (masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407873900/407873900 [00:16<00:00, 24951789.04B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed to load BERT  25.242907524108887\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#Cargar el tokenizer pre-entrenado\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Cargamos el modelo preparado para predecir una palabra ocultada (masked)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "end = time.time()\n",
    "print (\"Time Elapsed to load BERT \",end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción de las palabras que pueden ocupar un blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Función para predecir la 30 palabras que pueden llenar un blank según su probabilidad \n",
    "# Eg: The Sun is more ____ 4 billion years old.\n",
    "\n",
    "def get_predicted_words(text):\n",
    "    # Añadimos al texto los tokens de inicio [CLS] y token de separador (fin) [SEP]\n",
    "    # Sustituimos '_______' por el token MASK\n",
    "    text = \"[CLS] \" + text.replace(\"____\", \"[MASK]\") + \" [SEP]\"\n",
    "    # text= '[CLS] Tom has fully [MASK] from his illness. [SEP]'\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    # Mostrar los tokens de la frase según el tokenizador de BERT\n",
    "    print(\"tokenized sentence: \",tokenized_text,\"\\n\")\n",
    "    # Obtener el índice del token '[MASK]'\n",
    "    masked_index = tokenized_text.index('[MASK]')\n",
    "    # Convertir los tokens a su índices según el vocabulario del modelo BERT \n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    print(\"tokenized sentence indexes: \",indexed_tokens,\"\\n\")\n",
    "\n",
    "    # Crear el tensor del segmento. Se inicia con un tensor de longitud del texto tokenizado con índices igual a 0 .\n",
    "    segments_ids = [0] * len(tokenized_text)\n",
    "    print(\"SEG IDS\", segments_ids)\n",
    "\n",
    "    # Convertir los inputs a tensores PyTorch\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    # Predecir el token enmascarado según el modelo\n",
    "    with torch.no_grad():\n",
    "        predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "    # Obtener un número k de opciones candidatas a sustituir la palabra oculta. \n",
    "    k = 30\n",
    "    predicted_index, predicted_index_values = torch.topk(predictions[0, masked_index], k)\n",
    "    print(predicted_index)\n",
    "    # Los índices de los tokens del vocabulario que son candidatos se transforman a tokens\n",
    "    predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_index_values.tolist())\n",
    "    # Lista de tokens que no contienen signos de puntuación\n",
    "    filtered_tokens_to_remove_punctuation = []\n",
    "    # Retornar las opciones que tienen signos de puntuación.\n",
    "    for token in predicted_tokens:\n",
    "        if re.match(\"^[a-zA-Z0-9_]*$\", token):\n",
    "            filtered_tokens_to_remove_punctuation.append(token)\n",
    "        \n",
    "    return filtered_tokens_to_remove_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentence:  They all look tiny ____ they are so far away from the Earth. \n",
      "\n",
      "tokenized sentence:  ['[CLS]', 'they', 'all', 'look', 'tiny', '[MASK]', 'they', 'are', 'so', 'far', 'away', 'from', 'the', 'earth', '.', '[SEP]'] \n",
      "\n",
      "tokenized sentence indexes:  [101, 2027, 2035, 2298, 4714, 103, 2027, 2024, 2061, 2521, 2185, 2013, 1996, 3011, 1012, 102] \n",
      "\n",
      "SEG IDS [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "tensor([10.5270,  9.8855,  9.8194,  9.4380,  8.4528,  8.0976,  8.0250,  7.7745,\n",
      "         7.3686,  7.2621,  7.0900,  6.6434,  5.8249,  5.7217,  5.3661,  5.1552,\n",
      "         5.0250,  4.8781,  4.7832,  4.5813,  4.5462,  4.4355,  4.3125,  4.2794,\n",
      "         4.1162,  4.0410,  4.0337,  3.9101,  3.8251,  3.6499])\n",
      "predicted choices:  ['because', 'and', 'but', 'as', 'since', 'like', 'when', 'considering', 'for', 'except', 'though', 'that', 'yet', 'although', 'while', 'now', 'if', 'where', 'here', 'even', 'so', 'after', 'from', 'given']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"They all look tiny ____ they are so far away from the Earth.\"\n",
    "print (\"original sentence: \",sentence,\"\\n\")\n",
    "predicted_words = get_predicted_words(sentence)\n",
    "print (\"predicted choices: \", predicted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similitud entre frases con palabras polisémicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar spacy-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install spacy-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener el modelo BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m spacy download en_trf_bertbaseuncased_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple shares rose on the news. vs Apple sold fewer iPhones this quarter. : Similarity:  0.73428535\n",
      "Apple shares rose on the news. vs Apple pie is delicious. : Similarity:  0.43365782\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#Cargar el modelo\n",
    "nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
    "\n",
    "#Procesar los textos a comparar según el modelo\n",
    "text1 = nlp(\"Apple shares rose on the news.\")\n",
    "text2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
    "text3 = nlp(\"Apple pie is delicious.\")\n",
    "\n",
    "print(text1, \"vs\", text2, \":\", \"Similarity: \", text1[0].similarity(text2[0]))\n",
    "print(text1, \"vs\", text3, \":\", \"Similarity: \", text1[0].similarity(text3[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
