{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5297148",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8badb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librerías\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5371111",
   "metadata": {},
   "source": [
    "# Preprocesamiento y limpieza de la BD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8492bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ficheros de entrada\n",
    "ED_TRAIN1 = \"data/ED_train1.csv\"\n",
    "ED_TRAIN2 = \"data/ED_train2.csv\"\n",
    "ED_VALID = \"data/ED_valid.csv\"\n",
    "ED_TEST = \"data/ED_test.csv\"\n",
    "\n",
    "# Ficheros procesados\n",
    "ED_TRAIN_P1 = \"data/ED_train_p1.csv\"\n",
    "ED_TRAIN_P2 = \"data/ED_train_p2.csv\"\n",
    "ED_VALID_P = \"data/ED_valid_p.csv\"\n",
    "ED_TEST_P = \"data/ED_test_p.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3a3dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BD_preprocessing(csv_in, csv_out, s):\n",
    "    '''\n",
    "    Procesa los ficheros .csv correspondientes a la BD EMPATHETICDIALOGUES que servirán como \n",
    "    entrada para el entrenamiento del codificador BERT\n",
    "    \n",
    "    Parámetros:\n",
    "        csv_in: Nombre del fichero de entrada\n",
    "        csv_out: Nombre del fichero de salida\n",
    "        s: separador en los ficheros .csv\n",
    "    '''\n",
    "    df = pd.read_csv(csv_in,sep=s) \n",
    "    \n",
    "    len_max = 0\n",
    "    # Pone en una misma fila, las parejas de turnos de conversación\n",
    "    df['utterance2'] = \"\"\n",
    "    conv = df['conv_id'][0]\n",
    "    for index, row in df.iterrows(): \n",
    "        if (index > 0) and (conv == row['conv_id']): # Para todas las lineas de la misma conversación.\n",
    "            df[\"utterance2\"][index-1] = row[\"utterance\"]\n",
    "        else:\n",
    "            conv = row['conv_id'] # Cambio al siguiente diálogo.\n",
    "\n",
    "    # Borra las lineas huérfanas. Corresponden al último turno de cada conversación.\n",
    "    df = df.drop(df[df['utterance2']==\"\"].index)\n",
    "    \n",
    "   \n",
    "    # Corregimos sustituyendo \"_comma_\" por \",\"\n",
    "    df['utterance']= df['utterance'].str.replace(\"_comma_\", \",\", case = False) \n",
    "    df['utterance2']= df['utterance2'].str.replace(\"_comma_\", \",\", case = False)  \n",
    "    \n",
    "    # Asignación de la clasificación según la emoción\n",
    "    df['emotion'] = df['context']\n",
    "    \n",
    "    # Listas de emociones según nivel de recompensa\n",
    "    nivel1 = ['anxious','devastated','disappointed','disgusted','furious','jealous','lonely','terrified'] # Recompensa -2\n",
    "    nivel2 = ['afraid','angry','annoyed','apprehensive','ashamed','embarrassed','guilty','sad'] # Recompensa -1\n",
    "    nivel3 = ['caring','confident','content','joyful','nostalgic','prepared','sentimental','trusting'] # Recompensa 1\n",
    "    nivel4 = ['anticipating','excited','faithful','grateful','hopeful','impressed','proud','surprised'] # Recompensa 2\n",
    "\n",
    "    # Sustituir la emoción con el nivel que le corresponde\n",
    "    # En primer lugar informé con 1,2,3,4\n",
    "    df['emotion'] = df['emotion'].replace(nivel1, 0)\n",
    "    df['emotion'] = df['emotion'].replace(nivel2, 1)\n",
    "    df['emotion'] = df['emotion'].replace(nivel3, 2)\n",
    "    df['emotion'] = df['emotion'].replace(nivel4, 3)\n",
    "    \n",
    "    # Eliminar las columnas que no necesitamos\n",
    "    df = df.drop(['conv_id','utterance_idx','context','prompt','speaker_idx','selfeval','tags','head9','head10','head11','head12'],axis=1)\n",
    "    \n",
    "    # Guardar csv\n",
    "    df.to_csv(csv_out,index=False,sep=';')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c2d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_preprocessing(ED_TRAIN1,ED_TRAIN_P1,';')\n",
    "BD_preprocessing(ED_TRAIN2,ED_TRAIN_P2,';')\n",
    "BD_preprocessing(ED_VALID,ED_VALID_P,',')\n",
    "BD_preprocessing(ED_TEST,ED_TEST_P,',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db224878",
   "metadata": {},
   "source": [
    "# 4. Entrenamiento aprendizaje reforzado con REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0918af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
