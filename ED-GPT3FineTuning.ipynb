{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partir del ejemplo\n",
    " \n",
    "https://shreyz-max.medium.com/finetuning-gpt3-ba07a10fa9d3\n",
    "\n",
    "Adaptamos a nuestra base de datos ED\n",
    "Ver Notebook en JokeSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n2oPmVrJj8oQ",
    "outputId": "19752767-f058-47d0-eecd-015fb1d36b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.7/site-packages (0.25.0)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /opt/anaconda3/lib/python3.7/site-packages (from openai) (1.2.0.62)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/lib/python3.7/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: pandas>=1.2.3 in /opt/anaconda3/lib/python3.7/site-packages (from openai) (1.3.5)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.7/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in /opt/anaconda3/lib/python3.7/site-packages (from openai) (3.0.10)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from openai) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.7/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: et_xmlfile in /opt/anaconda3/lib/python3.7/site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=1.2.3->openai) (2022.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#download openai\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerias\n",
    "import openai\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY de openai\n",
    "openai.api_key = 'here_the_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Qvkir7-Ej-sk",
    "outputId": "91dfa9eb-ddf8-4811-9b75-bce537e8b003"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>utterance2</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32275</th>\n",
       "      <td>It was a marketing job</td>\n",
       "      <td>What traits do you have that make you think yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32276</th>\n",
       "      <td>On the first date date I expect nothing more t...</td>\n",
       "      <td>Its nice to be prepared</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32277</th>\n",
       "      <td>Its nice to be prepared</td>\n",
       "      <td>Absolutely.  Never fails</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32278</th>\n",
       "      <td>Absolutely.  Never fails</td>\n",
       "      <td>I will have to start doing that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32279</th>\n",
       "      <td>Absolutely.  Never fails</td>\n",
       "      <td>I will have to start doing that</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utterance  \\\n",
       "32275                             It was a marketing job   \n",
       "32276  On the first date date I expect nothing more t...   \n",
       "32277                            Its nice to be prepared   \n",
       "32278                           Absolutely.  Never fails   \n",
       "32279                           Absolutely.  Never fails   \n",
       "\n",
       "                                              utterance2  emotion  \n",
       "32275  What traits do you have that make you think yo...        0  \n",
       "32276                            Its nice to be prepared        2  \n",
       "32277                           Absolutely.  Never fails        2  \n",
       "32278                    I will have to start doing that        2  \n",
       "32279                    I will have to start doing that        2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar la primera parte del set de entrenamiento\n",
    "df1 = pd.read_csv('ED_train_p1.csv',sep=\";\")\n",
    "#df1.head()\n",
    "df1.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>utterance2</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32355</th>\n",
       "      <td>Oh hey that's awesome!  That is awesome right?</td>\n",
       "      <td>It is soooo awesome.  We have been wanting a b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32356</th>\n",
       "      <td>It is soooo awesome.  We have been wanting a b...</td>\n",
       "      <td>That is awesome!!!! Congratulations!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32357</th>\n",
       "      <td>I woke up this morning to my wife telling me s...</td>\n",
       "      <td>Oh hey that's awesome!  That is awesome right?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32358</th>\n",
       "      <td>Oh hey that's awesome!  That is awesome right?</td>\n",
       "      <td>It is soooo awesome.  We have been wanting a b...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32359</th>\n",
       "      <td>It is soooo awesome.  We have been wanting a b...</td>\n",
       "      <td>That is awesome!!!! Congratulations!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               utterance  \\\n",
       "32355     Oh hey that's awesome!  That is awesome right?   \n",
       "32356  It is soooo awesome.  We have been wanting a b...   \n",
       "32357  I woke up this morning to my wife telling me s...   \n",
       "32358     Oh hey that's awesome!  That is awesome right?   \n",
       "32359  It is soooo awesome.  We have been wanting a b...   \n",
       "\n",
       "                                              utterance2  emotion  \n",
       "32355  It is soooo awesome.  We have been wanting a b...        3  \n",
       "32356               That is awesome!!!! Congratulations!        3  \n",
       "32357     Oh hey that's awesome!  That is awesome right?        3  \n",
       "32358  It is soooo awesome.  We have been wanting a b...        3  \n",
       "32359               That is awesome!!!! Congratulations!        3  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar la segunda parte del set de entrenamiento\n",
    "df2 = pd.read_csv('ED_train_p2.csv',sep=\";\")\n",
    "#df1.head()\n",
    "df2.tail()\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32280\n",
      "32360\n",
      "64640\n"
     ]
    }
   ],
   "source": [
    "print(len(df1))\n",
    "print(len(df2))\n",
    "print(len(df_ED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               utterance  \\\n",
      "0      I remember going to see the fireworks with my ...   \n",
      "1      Was this a friend you were in love with, or ju...   \n",
      "2                    This was a best friend. I miss her.   \n",
      "3                                    Where has she gone?   \n",
      "4                                     We no longer talk.   \n",
      "...                                                  ...   \n",
      "32355     Oh hey that's awesome!  That is awesome right?   \n",
      "32356  It is soooo awesome.  We have been wanting a b...   \n",
      "32357  I woke up this morning to my wife telling me s...   \n",
      "32358     Oh hey that's awesome!  That is awesome right?   \n",
      "32359  It is soooo awesome.  We have been wanting a b...   \n",
      "\n",
      "                                              utterance2  emotion  \n",
      "0      Was this a friend you were in love with, or ju...        2  \n",
      "1                    This was a best friend. I miss her.        2  \n",
      "2                                    Where has she gone?        2  \n",
      "3                                     We no longer talk.        2  \n",
      "4      Oh was this something that happened because of...        2  \n",
      "...                                                  ...      ...  \n",
      "32355  It is soooo awesome.  We have been wanting a b...        3  \n",
      "32356               That is awesome!!!! Congratulations!        3  \n",
      "32357     Oh hey that's awesome!  That is awesome right?        3  \n",
      "32358  It is soooo awesome.  We have been wanting a b...        3  \n",
      "32359               That is awesome!!!! Congratulations!        3  \n",
      "\n",
      "[64640 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Unir las BD's tomando solamente los turnos (utternace y utterance2)\n",
    "df_ED = pd.concat([df1,df2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>utterance2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>Where has she gone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>We no longer talk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>Oh was this something that happened because of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           utterance  \\\n",
       "0  I remember going to see the fireworks with my ...   \n",
       "1  Was this a friend you were in love with, or ju...   \n",
       "2                This was a best friend. I miss her.   \n",
       "3                                Where has she gone?   \n",
       "4                                 We no longer talk.   \n",
       "\n",
       "                                          utterance2  \n",
       "0  Was this a friend you were in love with, or ju...  \n",
       "1                This was a best friend. I miss her.  \n",
       "2                                Where has she gone?  \n",
       "3                                 We no longer talk.  \n",
       "4  Oh was this something that happened because of...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos la columna emotion\n",
    "df_ED = df_ED.drop(['emotion'], axis=1)\n",
    "df_ED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Was this a friend you were in love with, or ju...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>Where has she gone?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>We no longer talk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>Oh was this something that happened because of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  I remember going to see the fireworks with my ...   \n",
       "1  Was this a friend you were in love with, or ju...   \n",
       "2                This was a best friend. I miss her.   \n",
       "3                                Where has she gone?   \n",
       "4                                 We no longer talk.   \n",
       "\n",
       "                                          completion  \n",
       "0  Was this a friend you were in love with, or ju...  \n",
       "1                This was a best friend. I miss her.  \n",
       "2                                Where has she gone?  \n",
       "3                                 We no longer talk.  \n",
       "4  Oh was this something that happened because of...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cambiamos el nombre de las columna para adaptar el dataset a lo que necesita GPT3\n",
    "df_ED.rename(columns={'utterance':'prompt',\n",
    "                        'utterance2':'completion'},\n",
    "               inplace=True)\n",
    "\n",
    "df_ED.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7DGJc2yJkikx"
   },
   "outputs": [],
   "source": [
    "#saving the new csv file\n",
    "df_ED.to_csv('ED.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-R6FSg9kzF9",
    "outputId": "ea914898-9245-406b-bf6a-906ffb89c4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Based on your file extension, your file is formatted as a CSV file\n",
      "- Your file contains 64640 prompt-completion pairs\n",
      "- The input file should contain exactly two columns/keys per row. Additional columns/keys present are: ['Unnamed: 0']\n",
      "  WARNING: Some of the additional columns/keys contain `Unnamed: 0` in their name. These will be ignored, and the column/key `Unnamed: 0` will be used instead. This could also result from a duplicate column/key in the provided file.\n",
      "- `completion` column/key should not contain empty strings. These are rows: [30548, 30549, 30550]\n",
      "- There are 23 duplicated prompt-completion sets. These are rows: [16057, 16058, 32115, 32276, 32382, 32463, 39726, 43536, 43537, 44501, 44704, 44913, 45911, 46875, 48073, 48439, 50479, 50592, 50593, 51052, 64634, 64635, 64636]\n",
      "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
      "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
      "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://beta.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Necessary] Your format `CSV` will be converted to `JSONL`\n",
      "- [Necessary] Remove additional columns/keys: ['Unnamed: 0']\n",
      "- [Necessary] Remove 3 rows with empty completions\n",
      "- [Recommended] Remove 23 duplicate rows [Y/n]: - [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: - [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: - [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: \n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: \n",
      "Wrote modified file to `ED_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"ED_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 2.19 days to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "#converting csv to jsonl format because that is the format GPT3 can be finetuned in\n",
    "!yes | openai tools fine_tunes.prepare_data -f 'ED.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62H9dyNLlBqx",
    "outputId": "2aecbd2e-25ca-460d-f471-44fa7b557892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"bytes\": 10768083,\n",
      "  \"created_at\": 1669844649,\n",
      "  \"filename\": \"file\",\n",
      "  \"id\": \"file-NZ6ExR6dig3ua6VbPwj0l3Qh\",\n",
      "  \"object\": \"file\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#creating a file id from the jsonl file\n",
    "# Parece que se queda colgado\n",
    "with open(\"ED_prepared.jsonl\") as f:\n",
    "    response = openai.File.create(file=f, purpose='fine-tune')\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxzuwSQVlL-S",
    "outputId": "74e237ef-63cc-4f73-8357-7c8140d87af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created_at\": 1669844848,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"created_at\": 1669844848,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-0ErXUrLbYOu7EBJULWIxrpc1\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": null,\n",
      "    \"learning_rate_multiplier\": null,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.01\n",
      "  },\n",
      "  \"id\": \"ft-0ErXUrLbYOu7EBJULWIxrpc1\",\n",
      "  \"model\": \"ada\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"organization_id\": \"org-xSwUUXjHMLby2b8IceH3t8iK\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"pending\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"bytes\": 10768083,\n",
      "      \"created_at\": 1669844649,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-NZ6ExR6dig3ua6VbPwj0l3Qh\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1669844848,\n",
      "  \"validation_files\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#the file id is then used to create finetune model\n",
    "response = openai.FineTune.create(training_file=\"file-NZ6ExR6dig3ua6VbPwj0l3Qh\", model='ada')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcXju1DflUir",
    "outputId": "5e8de77c-ecd8-4f3a-8088-e57f7c1dc971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created_at\": 1669844848,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"created_at\": 1669844848,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-0ErXUrLbYOu7EBJULWIxrpc1\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669844853,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune costs $3.50\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669844854,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune enqueued. Queue number: 0\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669844865,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune started\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"learning_rate_multiplier\": 0.2,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.01\n",
      "  },\n",
      "  \"id\": \"ft-0ErXUrLbYOu7EBJULWIxrpc1\",\n",
      "  \"model\": \"ada\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"organization_id\": \"org-xSwUUXjHMLby2b8IceH3t8iK\",\n",
      "  \"result_files\": [],\n",
      "  \"status\": \"running\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"bytes\": 10768083,\n",
      "      \"created_at\": 1669844649,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-NZ6ExR6dig3ua6VbPwj0l3Qh\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1669844865,\n",
      "  \"validation_files\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#this shows how much training has been done\n",
    "# PRIMERA CONSULTA\n",
    "# NO REEJECUTAR\n",
    "response = openai.FineTune.retrieve(id=\"ft-0ErXUrLbYOu7EBJULWIxrpc1\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"created_at\": 1669844848,\n",
      "  \"events\": [\n",
      "    {\n",
      "      \"created_at\": 1669844848,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Created fine-tune: ft-0ErXUrLbYOu7EBJULWIxrpc1\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669844853,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune costs $3.50\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669844854,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune enqueued. Queue number: 0\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669844865,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune started\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669845762,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669846823,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669846917,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669846981,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune started\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669847359,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed epoch 1/4\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669847718,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed epoch 2/4\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669848077,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed epoch 3/4\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669848438,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Completed epoch 4/4\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669848462,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded model: ada:ft-mabel-2022-11-30-22-47-42\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669848463,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Uploaded result file: file-0qJ30HrC4IvK58hiDvjIKcLa\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    },\n",
      "    {\n",
      "      \"created_at\": 1669848463,\n",
      "      \"level\": \"info\",\n",
      "      \"message\": \"Fine-tune succeeded\",\n",
      "      \"object\": \"fine-tune-event\"\n",
      "    }\n",
      "  ],\n",
      "  \"fine_tuned_model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
      "  \"hyperparams\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"learning_rate_multiplier\": 0.2,\n",
      "    \"n_epochs\": 4,\n",
      "    \"prompt_loss_weight\": 0.01\n",
      "  },\n",
      "  \"id\": \"ft-0ErXUrLbYOu7EBJULWIxrpc1\",\n",
      "  \"model\": \"ada\",\n",
      "  \"object\": \"fine-tune\",\n",
      "  \"organization_id\": \"org-xSwUUXjHMLby2b8IceH3t8iK\",\n",
      "  \"result_files\": [\n",
      "    {\n",
      "      \"bytes\": 126823,\n",
      "      \"created_at\": 1669848463,\n",
      "      \"filename\": \"compiled_results.csv\",\n",
      "      \"id\": \"file-0qJ30HrC4IvK58hiDvjIKcLa\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune-results\",\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"status\": \"succeeded\",\n",
      "  \"training_files\": [\n",
      "    {\n",
      "      \"bytes\": 10768083,\n",
      "      \"created_at\": 1669844649,\n",
      "      \"filename\": \"file\",\n",
      "      \"id\": \"file-NZ6ExR6dig3ua6VbPwj0l3Qh\",\n",
      "      \"object\": \"file\",\n",
      "      \"purpose\": \"fine-tune\",\n",
      "      \"status\": \"processed\",\n",
      "      \"status_details\": null\n",
      "    }\n",
      "  ],\n",
      "  \"updated_at\": 1669848463,\n",
      "  \"validation_files\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#this shows how much training has been done\n",
    "response = openai.FineTune.retrieve(id=\"ft-0ErXUrLbYOu7EBJULWIxrpc1\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando el modelo GPT3 entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar librerias\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY de openai\n",
    "openai.api_key = 'Here-the-API-KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6N6nSmWyy7DJJ69zccq1Cu13y0Miv at 0x1111d6d10> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" but I do like halls. -> Hall steps sound great!\\n\\nHow did you end up getting it?\\n\\nFun\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1670965690,\n",
       "  \"id\": \"cmpl-6N6nSmWyy7DJJ69zccq1Cu13y0Miv\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 25,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 30\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I don't like Christmas\", max_tokens=25, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FArVoEIlXTW",
    "outputId": "2a345c15-0075-4395-d973-15bbd0570673"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6Ic7mHgvfS1LaMbLw2v03B0ICIz5X at 0x11a2c5350> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"              > why xxx\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669894474,\n",
       "  \"id\": \"cmpl-6Ic7mHgvfS1LaMbLw2v03B0ICIz5X\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 18,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 22\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I hate ... \", max_tokens=18, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6Ic8URaDOS1YBPOfRHbANiLetLU0b at 0x11a2c5410> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> I am sure you are gonna win it, I just hope you do!!\\n\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669894518,\n",
       "  \"id\": \"cmpl-6Ic8URaDOS1YBPOfRHbANiLetLU0b\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 18,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 23\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"Knock Knock... \", max_tokens=18, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6Ic99CVn65CUDpOxtO6hEaGSvip02 at 0x11a2c5dd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> oh wow that did sound scary! why was it so scary?\\n\\n120 on\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669894559,\n",
       "  \"id\": \"cmpl-6Ic99CVn65CUDpOxtO6hEaGSvip02\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 18,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 23\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I want to die \", max_tokens=18, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IcANrP9SygyraSNx1yWL8MXV0O1P at 0x11a2e1710> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" I don't have the right to say anything right now, I'm sad -> I'm\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669894635,\n",
       "  \"id\": \"cmpl-6IcANrP9SygyraSNx1yWL8MXV0O1P\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 18,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 23\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"My father dies. \", max_tokens=21, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IcCcjUV2SnZBQbiWKtU4Wor4plkC at 0x11a2e1bf0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Then will you be responsible for him? -> I will be, but I'm going to be fine.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669894774,\n",
       "  \"id\": \"cmpl-6IcCcjUV2SnZBQbiWKtU4Wor4plkC\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 26\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"My father dies. \", max_tokens=21, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IcDuqPQ1hl4TtXD1QHbCfeW3S2Cc at 0x11a2e1dd0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> I am sorry, condolences? I feel sorry for you!\\n\\nA dad is not living till\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669894854,\n",
       "  \"id\": \"cmpl-6IcDuqPQ1hl4TtXD1QHbCfeW3S2Cc\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 26\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"My father dies. \", max_tokens=21, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IfNrjCGYZCZY5Nd7AkHi5fFc5ayg at 0x11a2ef4d0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"You can go to a downtown union meeting and ask for a job! -> I am thinking about it.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669907003,\n",
       "  \"id\": \"cmpl-6IfNrjCGYZCZY5Nd7AkHi5fFc5ayg\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 26\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I got fired. \", max_tokens=21, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IfQyh7HW7IZV4emsz7LRLJMF9sD3 at 0x11a2e1cb0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> I know I will do that this weekend\\n\\nI should have found my friend that good job in\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669907196,\n",
       "  \"id\": \"cmpl-6IfQyh7HW7IZV4emsz7LRLJMF9sD3\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 15,\n",
       "    \"total_tokens\": 36\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"You can go to a downtown union meeting and ask for a job! \", max_tokens=21, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IfSKfqxXFT29aOoqwZ1s9thqolfh at 0x11a284650> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> That's smart. No one wants anyone on their team to fail.\\n\\now! What change\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669907280,\n",
       "  \"id\": \"cmpl-6IfSKfqxXFT29aOoqwZ1s9thqolfh\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 9,\n",
       "    \"total_tokens\": 30\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I know I will do that this weekend.\", max_tokens=21, temperature=1)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6IfTVmjvoHd2wHEvqwvdyj066x5XB at 0x11a284590> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" You deserve to be proud of your performance and hopefully do well in the conference next season! -> I'll\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1669907353,\n",
       "  \"id\": \"cmpl-6IfTVmjvoHd2wHEvqwvdyj066x5XB\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 14,\n",
       "    \"total_tokens\": 35\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"That's smart. No one wants anyone on their team to fail.\", max_tokens=21, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6N7AcngythBLkjSYm4unngfeWsNT4 at 0x12208eef0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> That's terrible. Have you thought about finding another job?\\n\\nHow sad. \\n\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1670967126,\n",
       "  \"id\": \"cmpl-6N7AcngythBLkjSYm4unngfeWsNT4\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 25\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I got fired.\", max_tokens=21, temperature=0.8)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6N7B1LifwiVb6z2S2RqQDIVFUkthL at 0x122099290> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" I bet you feel so bad. -> I am so heartbroken.\\n\\nI have been working my\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1670967151,\n",
       "  \"id\": \"cmpl-6N7B1LifwiVb6z2S2RqQDIVFUkthL\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 21,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 25\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I got fired.\", max_tokens=21, temperature=0.8)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6N7IL31FthtR6faMZEb8pdtMBjVsD at 0x122099bf0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" -> Oh no!  Don't worry and I'm sure you will be okay!  I am so thankful for your wife!  She would never leave me like that.  I hope you're back to the strong,\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1670967605,\n",
       "  \"id\": \"cmpl-6N7IL31FthtR6faMZEb8pdtMBjVsD\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 45,\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"total_tokens\": 50\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"My leg was broken.\", max_tokens=45, temperature=0.8)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6N6jgPVuvFrIyMib3LpcFUwzl6Qsc at 0x121406710> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"length\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" of exhaustion lol. How many times have you tried to go through all this along |>\\n\\nand it?ve happened\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1670965456,\n",
       "  \"id\": \"cmpl-6N6jgPVuvFrIyMib3LpcFUwzl6Qsc\",\n",
       "  \"model\": \"ada:ft-mabel-2022-11-30-22-47-42\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 25,\n",
       "    \"prompt_tokens\": 4,\n",
       "    \"total_tokens\": 29\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the inference\n",
    "ft_model = \"ada:ft-mabel-2022-11-30-22-47-42\"\n",
    "res = openai.Completion.create(model=ft_model, prompt=\"I want to die\", max_tokens=25, temperature=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOY ADAPTANDO POR AQUÍ"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "FineTune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
