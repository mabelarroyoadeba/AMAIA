{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE8KKbYHbRgs"
   },
   "source": [
    "# Fine tunning modelo BERT para generación de recompensa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3873,
     "status": "ok",
     "timestamp": 1669927036289,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "3VgW3Um4bAUi",
    "outputId": "fdbbf839-18af-4538-eb8e-a1b5d4874cb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:07.007261Z",
     "iopub.status.busy": "2022-12-02T17:32:07.005402Z",
     "iopub.status.idle": "2022-12-02T17:32:07.016200Z",
     "shell.execute_reply": "2022-12-02T17:32:07.015207Z",
     "shell.execute_reply.started": "2022-12-02T17:32:07.007169Z"
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1669927068972,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "Mc8cWZgOo-fw"
   },
   "outputs": [],
   "source": [
    "# Instalar librerías\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:35.400053Z",
     "iopub.status.busy": "2022-12-02T17:32:35.399643Z",
     "iopub.status.idle": "2022-12-02T17:32:35.411225Z",
     "shell.execute_reply": "2022-12-02T17:32:35.410266Z",
     "shell.execute_reply.started": "2022-12-02T17:32:35.400020Z"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1669927070721,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "pvf0gheBcUUz",
    "outputId": "e7c070cc-1daa-4352-870f-58d2961275c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 21\n",
    "MAX_LEN = 125\n",
    "BATCH_SIZE = 32\n",
    "DATASET_TRAIN1 = '/kaggle/input/empathetic/ED_train_p1.csv'\n",
    "DATASET_TRAIN2 = '/kaggle/input/empathetic/ED_train_p2.csv'\n",
    "DATASET_VALID = '/kaggle/input/empathetic/ED_train_p1.csv'\n",
    "NCLASSES = 4\n",
    "\n",
    "# Las siguentes lineas son necesarias?\n",
    "#np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:38.854601Z",
     "iopub.status.busy": "2022-12-02T17:32:38.854183Z",
     "iopub.status.idle": "2022-12-02T17:32:39.342522Z",
     "shell.execute_reply": "2022-12-02T17:32:39.341464Z",
     "shell.execute_reply.started": "2022-12-02T17:32:38.854566Z"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1669927076720,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "ZaCju5FucUXr"
   },
   "outputs": [],
   "source": [
    "df_train1 = pd.read_csv(DATASET_TRAIN1, sep = ';')\n",
    "df_train2 = pd.read_csv(DATASET_TRAIN2, sep = ';')\n",
    "df_valid = pd.read_csv(DATASET_VALID, sep = ';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:43.191241Z",
     "iopub.status.busy": "2022-12-02T17:32:43.190769Z",
     "iopub.status.idle": "2022-12-02T17:32:43.211248Z",
     "shell.execute_reply": "2022-12-02T17:32:43.210254Z",
     "shell.execute_reply.started": "2022-12-02T17:32:43.191200Z"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1669927079588,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "8-NpwaG_qAuy",
    "outputId": "0afc07bc-758c-4808-8748-2a0bc5edcd6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "utterance     object\n",
       "utterance2    object\n",
       "emotion        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1.head()\n",
    "df_train1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:46.809846Z",
     "iopub.status.busy": "2022-12-02T17:32:46.809452Z",
     "iopub.status.idle": "2022-12-02T17:32:48.200700Z",
     "shell.execute_reply": "2022-12-02T17:32:48.199455Z",
     "shell.execute_reply.started": "2022-12-02T17:32:46.809814Z"
    },
    "executionInfo": {
     "elapsed": 349,
     "status": "ok",
     "timestamp": 1669927081955,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "rKf_vsK7cUak"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458e0e33084f44978b34f8ff5116a087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398ca9927ab74b4ab18b1220f93ccf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:50.990651Z",
     "iopub.status.busy": "2022-12-02T17:32:50.990287Z",
     "iopub.status.idle": "2022-12-02T17:32:50.997744Z",
     "shell.execute_reply": "2022-12-02T17:32:50.996553Z",
     "shell.execute_reply.started": "2022-12-02T17:32:50.990621Z"
    },
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1669927084552,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "qGd8VN_3cUdr"
   },
   "outputs": [],
   "source": [
    "utterance1 = \"\"\n",
    "utterance2 = \"\"\n",
    "encoding = tokenizer.encode_plus(\n",
    "    utterance1,\n",
    "    utterance2,\n",
    "    max_length = 125, # Numero máximo de palabras a codificar incluidos los tokens CLS y SEP\n",
    "    truncation = True,\n",
    "    add_special_tokens = True, # [CLS] y [SEP]\n",
    "    return_token_type_ids = False,\n",
    "    padding = 'max_length', # antes -->pad_to_max_length = True,\n",
    "    return_attention_mask = True,\n",
    "    return_tensors = 'pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:54.339506Z",
     "iopub.status.busy": "2022-12-02T17:32:54.339126Z",
     "iopub.status.idle": "2022-12-02T17:32:54.348307Z",
     "shell.execute_reply": "2022-12-02T17:32:54.347033Z",
     "shell.execute_reply.started": "2022-12-02T17:32:54.339478Z"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1669927087175,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "N5twz1iEcUgj"
   },
   "outputs": [],
   "source": [
    "class inputDataset(Dataset):\n",
    "    def __init__(self, utte1, utte2, labels, tokenizer,max_len):\n",
    "        self.utte1 = utte1\n",
    "        self.utte2 = utte2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utte1) # Indica la longitud de la base de datos. Se toma la longitud de esta columna (que es un array aquí) como podría ser la utte2 ya que son iguales.\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        utterance1 = str(self.utte1[item])\n",
    "        utterance2 = str(self.utte2[item])\n",
    "        label = self.labels[item]\n",
    "        encoding = tokenizer.encode_plus(\n",
    "            utterance1,\n",
    "            utterance2,\n",
    "            max_length = self.max_len,\n",
    "            truncation = True,\n",
    "            add_special_tokens = True,\n",
    "            return_token_type_ids = False,\n",
    "            padding = 'max_length', # Antes era --> pad_to_max_length = True\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'utterance1': utterance1,\n",
    "            'utterance2': utterance2,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:32:58.628100Z",
     "iopub.status.busy": "2022-12-02T17:32:58.627608Z",
     "iopub.status.idle": "2022-12-02T17:32:58.638285Z",
     "shell.execute_reply": "2022-12-02T17:32:58.637018Z",
     "shell.execute_reply.started": "2022-12-02T17:32:58.628058Z"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1669927090454,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "lIAkSjs2cUjV"
   },
   "outputs": [],
   "source": [
    "def data_loader(df, tokenizer, max_len, batch_size):\n",
    "    dataset = inputDataset(\n",
    "        utte1 = df.utterance.to_numpy(),\n",
    "        utte2 = df.utterance2.to_numpy(),\n",
    "        labels = df.emotion.to_numpy(),\n",
    "        tokenizer = tokenizer,\n",
    "        max_len = MAX_LEN\n",
    "    )\n",
    "\n",
    "    return DataLoader(dataset, batch_size = BATCH_SIZE, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:33:01.786426Z",
     "iopub.status.busy": "2022-12-02T17:33:01.785802Z",
     "iopub.status.idle": "2022-12-02T17:33:01.800678Z",
     "shell.execute_reply": "2022-12-02T17:33:01.799272Z",
     "shell.execute_reply.started": "2022-12-02T17:33:01.786388Z"
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1669927093096,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "iC4fZ0fIcUmM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "train_data_loader1 = data_loader(df_train1, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "train_data_loader2 = data_loader(df_train2, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "valid_data_loader = data_loader(df_valid, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:33:05.631609Z",
     "iopub.status.busy": "2022-12-02T17:33:05.631022Z",
     "iopub.status.idle": "2022-12-02T17:33:05.639171Z",
     "shell.execute_reply": "2022-12-02T17:33:05.637854Z",
     "shell.execute_reply.started": "2022-12-02T17:33:05.631573Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669927097789,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "VOnca-sVbhPX"
   },
   "outputs": [],
   "source": [
    "# EL MODELO!\n",
    "\n",
    "class BERTSentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(BERTSentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.drop = nn.Dropout(p=0.4)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        all_output, cls_output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        drop_output = self.drop(cls_output)\n",
    "        output = self.linear(drop_output)\n",
    "        return output, all_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-02T17:33:09.714010Z",
     "iopub.status.busy": "2022-12-02T17:33:09.712920Z",
     "iopub.status.idle": "2022-12-02T17:33:20.263244Z",
     "shell.execute_reply": "2022-12-02T17:33:20.262209Z",
     "shell.execute_reply.started": "2022-12-02T17:33:09.713942Z"
    },
    "executionInfo": {
     "elapsed": 1731,
     "status": "ok",
     "timestamp": 1669927104084,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "CanuNncKdXaF",
    "outputId": "eeb2f2f4-b6d8-4c8f-af4a-ec2c579ce84c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BERTSentimentClassifier(NCLASSES)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:33:20.266175Z",
     "iopub.status.busy": "2022-12-02T17:33:20.265431Z",
     "iopub.status.idle": "2022-12-02T17:33:20.278903Z",
     "shell.execute_reply": "2022-12-02T17:33:20.277829Z",
     "shell.execute_reply.started": "2022-12-02T17:33:20.266132Z"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1669927106618,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "Mansb6pfdn_H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# ENTRENAMIENTO \n",
    "# definición del entrenamiento\n",
    "EPOCHS = 5\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps1 = len(train_data_loader1) * EPOCHS\n",
    "total_steps2 = len(train_data_loader2) * EPOCHS\n",
    "\n",
    "scheduler1 = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = total_steps1\n",
    ")\n",
    "\n",
    "scheduler2 = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps = total_steps2\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T17:34:21.229912Z",
     "iopub.status.busy": "2022-12-02T17:34:21.229507Z",
     "iopub.status.idle": "2022-12-02T17:34:21.243707Z",
     "shell.execute_reply": "2022-12-02T17:34:21.242023Z",
     "shell.execute_reply.started": "2022-12-02T17:34:21.229879Z"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1669927110703,
     "user": {
      "displayName": "Mabel Arroyo Adeba",
      "userId": "00619475067745852919"
     },
     "user_tz": -60
    },
    "id": "ihoNOG0Zeuhz"
   },
   "outputs": [],
   "source": [
    "# Iteración entrenamiento\n",
    "def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for batch in data_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs, _ = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        correct_predictions += torch.sum(preds == labels) # las etiquetas que coinciden\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad() # resetear gredientes\n",
    "    return correct_predictions.double()/n_examples, np.mean(losses) # precisión y error\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    with torch.no_grad(): # sin modificar parámetros\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs, _ = model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "    return correct_predictions.double()/n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-output": false,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-02T11:11:21.805428Z",
     "iopub.status.busy": "2022-12-02T11:11:21.804655Z",
     "iopub.status.idle": "2022-12-02T13:06:54.840163Z",
     "shell.execute_reply": "2022-12-02T13:06:54.838534Z",
     "shell.execute_reply.started": "2022-12-02T11:11:21.805375Z"
    },
    "id": "etZPtXKozDyg",
    "outputId": "ac139870-12a8-4f33-bb38-79331d4dcb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 1.1542272365719406, accuracy: 0.4524783147459728\n",
      "Validación: Loss: 0.8878962537282995, accuracy: 0.6162329615861215\n",
      "\n",
      "Epoch 2 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.8871860907028168, accuracy: 0.6097583643122677\n",
      "Validación: Loss: 0.6383178822910348, accuracy: 0.7409541511771995\n",
      "\n",
      "Epoch 3 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.6639206005542791, accuracy: 0.7254956629491945\n",
      "Validación: Loss: 0.41699886976254824, accuracy: 0.8427199504337052\n",
      "\n",
      "Epoch 4 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.48024924359735693, accuracy: 0.8178438661710038\n",
      "Validación: Loss: 0.28390619020107893, accuracy: 0.9002478314745973\n",
      "\n",
      "Epoch 5 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.37159360498116084, accuracy: 0.8623915737298637\n",
      "Validación: Loss: 0.2235647847172615, accuracy: 0.9242565055762082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento 02.12.22\n",
    "# Con la primera parte de la BD\n",
    "# 5 epochs. dropout = 0.4 y cambiando pad_to_max_length a padding = 'max_length'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch {} de {}'.format(epoch+1, EPOCHS))\n",
    "    print('------------------')\n",
    "    train_acc, train_loss = train_model(\n",
    "        model, train_data_loader1, loss_fn, optimizer, device, scheduler1, len(df_train1)\n",
    "    )\n",
    "    test_acc, test_loss = eval_model(\n",
    "        model, valid_data_loader, loss_fn, device, len(df_valid)\n",
    "    )\n",
    "    print('Entrenamiento: Loss: {}, accuracy: {}'.format(train_loss, train_acc))\n",
    "    print('Validación: Loss: {}, accuracy: {}'.format(test_loss, test_acc))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-02T14:29:15.740748Z",
     "iopub.status.busy": "2022-12-02T14:29:15.740338Z",
     "iopub.status.idle": "2022-12-02T16:27:26.084937Z",
     "shell.execute_reply": "2022-12-02T16:27:26.083813Z",
     "shell.execute_reply.started": "2022-12-02T14:29:15.740711Z"
    },
    "id": "etZPtXKozDyg",
    "outputId": "ac139870-12a8-4f33-bb38-79331d4dcb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 1.141949704132893, accuracy: 0.45802354399008677\n",
      "Validación: Loss: 0.9004332335486757, accuracy: 0.6120198265179678\n",
      "\n",
      "Epoch 2 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.8892518614222202, accuracy: 0.6099442379182156\n",
      "Validación: Loss: 0.6712664625984944, accuracy: 0.7258674101610905\n",
      "\n",
      "Epoch 3 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.6935923562945412, accuracy: 0.7111214374225527\n",
      "Validación: Loss: 0.4855575600105483, accuracy: 0.8124225526641884\n",
      "\n",
      "Epoch 4 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.5358785963197293, accuracy: 0.7885997521685254\n",
      "Validación: Loss: 0.3531679416442709, accuracy: 0.8690210656753408\n",
      "\n",
      "Epoch 5 de 5\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.4342056518001528, accuracy: 0.8358426270136308\n",
      "Validación: Loss: 0.28936651448753353, accuracy: 0.8965303593556382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento 02.12.22\n",
    "# SEGUNDO intento, pues el anterior se paró y no pude grabar el modelo\n",
    "# Con la primera parte de la BD\n",
    "# 5 epochs. dropout = 0.4 y cambiando pad_to_max_length a padding = 'max_length'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch {} de {}'.format(epoch+1, EPOCHS))\n",
    "    print('------------------')\n",
    "    train_acc, train_loss = train_model(\n",
    "        model, train_data_loader1, loss_fn, optimizer, device, scheduler1, len(df_train1)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    test_acc, test_loss = eval_model(\n",
    "        model, valid_data_loader, loss_fn, device, len(df_valid)\n",
    "    )\n",
    "    print('Entrenamiento: Loss: {}, accuracy: {}'.format(train_loss, train_acc))\n",
    "    print('Validación: Loss: {}, accuracy: {}'.format(test_loss, test_acc))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-12-02T17:51:36.242500Z",
     "iopub.status.busy": "2022-12-02T17:51:36.241789Z",
     "iopub.status.idle": "2022-12-02T22:40:03.361793Z",
     "shell.execute_reply": "2022-12-02T22:40:03.360645Z",
     "shell.execute_reply.started": "2022-12-02T17:51:36.242461Z"
    },
    "id": "etZPtXKozDyg",
    "outputId": "ac139870-12a8-4f33-bb38-79331d4dcb28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.9904637025602957, accuracy: 0.563566131025958\n",
      "Validación: Loss: 0.848879939235001, accuracy: 0.6295848822800496\n",
      "\n",
      "Epoch 2 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.782461908837346, accuracy: 0.6684796044499383\n",
      "Validación: Loss: 0.6423804147096999, accuracy: 0.7388785625774473\n",
      "\n",
      "Epoch 3 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.572593158578478, accuracy: 0.7742274412855378\n",
      "Validación: Loss: 0.4720353667501534, accuracy: 0.8172862453531599\n",
      "\n",
      "Epoch 4 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.4051408894344421, accuracy: 0.8496600741656367\n",
      "Validación: Loss: 0.33891960886760264, accuracy: 0.8771995043370509\n",
      "\n",
      "Epoch 5 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.29132395563140995, accuracy: 0.8992274412855378\n",
      "Validación: Loss: 0.2519920706496056, accuracy: 0.9128872366790582\n",
      "\n",
      "Epoch 6 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.21854631049549778, accuracy: 0.9268232385661311\n",
      "Validación: Loss: 0.19646183434067105, accuracy: 0.936183395291202\n",
      "\n",
      "Epoch 7 de 7\n",
      "------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento: Loss: 0.18520454725026514, accuracy: 0.9387824474660075\n",
      "Validación: Loss: 0.2204032153965549, accuracy: 0.930731102850062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento 02.12.22\n",
    "# Tercer intento, pues el anterior se borró el .pth\n",
    "# Con la primera parte de la BD\n",
    "# y la segunda parte también\n",
    "# 5 epochs. dropout = 0.4 y cambiando pad_to_max_length a padding = 'max_length'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Epoch {} de {}'.format(epoch+1, EPOCHS))\n",
    "    print('------------------')\n",
    "    train_acc, train_loss = train_model(\n",
    "        model, train_data_loader1, loss_fn, optimizer, device, scheduler1, len(df_train1)\n",
    "    )\n",
    "    train_acc, train_loss = train_model(\n",
    "        model, train_data_loader2, loss_fn, optimizer, device, scheduler2, len(df_train2)\n",
    "    )\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model, valid_data_loader, loss_fn, device, len(df_valid)\n",
    "    )\n",
    "    print('Entrenamiento: Loss: {}, accuracy: {}'.format(train_loss, train_acc))\n",
    "    print('Validación: Loss: {}, accuracy: {}'.format(val_loss, val_acc))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T22:40:03.364886Z",
     "iopub.status.busy": "2022-12-02T22:40:03.363976Z",
     "iopub.status.idle": "2022-12-02T22:40:04.072456Z",
     "shell.execute_reply": "2022-12-02T22:40:04.071430Z",
     "shell.execute_reply.started": "2022-12-02T22:40:03.364845Z"
    },
    "id": "S16TnvgnQnEp"
   },
   "outputs": [],
   "source": [
    "# Grabar el modelo\n",
    "#PATH = '/content/drive/My Drive/TFM/reward4.pth'\n",
    "PATH = '/kaggle/working/reward4.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecutamos el modelo entrenado. Si no hemos ejecutado las anteriores debemos ejecutar la celda siguiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:57:19.979338Z",
     "iopub.status.busy": "2022-12-04T17:57:19.978966Z",
     "iopub.status.idle": "2022-12-04T17:57:34.912744Z",
     "shell.execute_reply": "2022-12-04T17:57:34.911437Z",
     "shell.execute_reply.started": "2022-12-04T17:57:19.979308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.13.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#RECUPERACION DEL MODELO\n",
    "!pip install transformers\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# DEFINICIÓN DEL MODELO\n",
    "class BERTSentimentClassifier(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(BERTSentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.drop = nn.Dropout(p=0.4)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, cls_output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            return_dict=False\n",
    "        )\n",
    "        drop_output = self.drop(cls_output)\n",
    "        output = self.linear(drop_output)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:57:39.295077Z",
     "iopub.status.busy": "2022-12-04T17:57:39.294111Z",
     "iopub.status.idle": "2022-12-04T17:57:39.411209Z",
     "shell.execute_reply": "2022-12-04T17:57:39.410142Z",
     "shell.execute_reply.started": "2022-12-04T17:57:39.295041Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:57:43.395073Z",
     "iopub.status.busy": "2022-12-04T17:57:43.394613Z",
     "iopub.status.idle": "2022-12-04T17:58:10.138701Z",
     "shell.execute_reply": "2022-12-04T17:58:10.137539Z",
     "shell.execute_reply.started": "2022-12-04T17:57:43.395036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2838a7093b274462840a46f6d5e71545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f57837326444bdd961d5e451afbde3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Cargamos los parámetros del modelo guardado\n",
    "NCLASSES = 4\n",
    "PATH = '/kaggle/input/rewardmodel/reward4.pth'\n",
    "model_loaded = BERTSentimentClassifier(NCLASSES)\n",
    "\n",
    "model_loaded.load_state_dict(torch.load(PATH))\n",
    "model_loaded.eval()\n",
    "model_loaded = model_loaded.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:58:13.759973Z",
     "iopub.status.busy": "2022-12-04T17:58:13.759603Z",
     "iopub.status.idle": "2022-12-04T17:58:13.770113Z",
     "shell.execute_reply": "2022-12-04T17:58:13.769126Z",
     "shell.execute_reply.started": "2022-12-04T17:58:13.759945Z"
    }
   },
   "outputs": [],
   "source": [
    "def classifySentiment_loaded(utterance1,utterance2):\n",
    "    encoding_review = tokenizer.encode_plus(\n",
    "        utterance1,\n",
    "        utterance2,\n",
    "        max_length = 125,\n",
    "        truncation = True,\n",
    "        add_special_tokens = True,\n",
    "        return_token_type_ids = False,\n",
    "        padding = 'max_length',\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt'\n",
    "        )\n",
    "  \n",
    "    input_ids = encoding_review['input_ids'].to(device)\n",
    "    attention_mask = encoding_review['attention_mask'].to(device)\n",
    "    output = model_loaded(input_ids, attention_mask)\n",
    "    _, prediction = torch.max(output, dim=1)\n",
    "    \n",
    "    #print('Nivel de emoción',prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:58:17.801638Z",
     "iopub.status.busy": "2022-12-04T17:58:17.801215Z",
     "iopub.status.idle": "2022-12-04T17:58:19.165957Z",
     "shell.execute_reply": "2022-12-04T17:58:19.164940Z",
     "shell.execute_reply.started": "2022-12-04T17:58:17.801603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4537e374dd1b448cb4186421f2053404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f251abfc8dbe403ab87a3041f72b0b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TOKENIZACIÓN\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T17:58:27.839567Z",
     "iopub.status.busy": "2022-12-04T17:58:27.839149Z",
     "iopub.status.idle": "2022-12-04T18:00:43.418260Z",
     "shell.execute_reply": "2022-12-04T18:00:43.417088Z",
     "shell.execute_reply.started": "2022-12-04T17:58:27.839535Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1145,  396,  287,  175],\n",
       "       [ 690,  949,  231,  146],\n",
       "       [ 239,  167, 1338,  326],\n",
       "       [ 290,  131,  784, 1112]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos el modelo con los datos de test\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DATASET_TEST = '/kaggle/input/ed-test/ED_test_p.csv'\n",
    "df_test = pd.read_csv(DATASET_TEST,sep=';')\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for index, row in df_test.iterrows(): \n",
    "    turno1 = row['utterance']\n",
    "    turno2 = row['utterance2']  \n",
    "    y_true.append(row['emotion'])\n",
    "    \n",
    "    emotion_pred = classifySentiment_loaded(turno1,turno2).item()\n",
    "    y_pred.append(emotion_pred)\n",
    "    \n",
    "# Creamos la matriz de confusión\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:01:33.209031Z",
     "iopub.status.busy": "2022-12-04T18:01:33.208665Z",
     "iopub.status.idle": "2022-12-04T18:01:33.223072Z",
     "shell.execute_reply": "2022-12-04T18:01:33.221941Z",
     "shell.execute_reply.started": "2022-12-04T18:01:33.209002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5405662621936712"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:03:09.467773Z",
     "iopub.status.busy": "2022-12-04T18:03:09.466685Z",
     "iopub.status.idle": "2022-12-04T18:03:09.804125Z",
     "shell.execute_reply": "2022-12-04T18:03:09.803060Z",
     "shell.execute_reply.started": "2022-12-04T18:03:09.467719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "matriz = confusion_matrix(y_true,y_pred)\n",
    "dataframe = pd.DataFrame(matriz)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True ,fmt=\".0f\", cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:03:26.354955Z",
     "iopub.status.busy": "2022-12-04T18:03:26.354568Z",
     "iopub.status.idle": "2022-12-04T18:03:26.376120Z",
     "shell.execute_reply": "2022-12-04T18:03:26.374870Z",
     "shell.execute_reply.started": "2022-12-04T18:03:26.354900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57164254, 0.47073413, 0.64637681, 0.47993095])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:03:30.918281Z",
     "iopub.status.busy": "2022-12-04T18:03:30.917910Z",
     "iopub.status.idle": "2022-12-04T18:03:30.937522Z",
     "shell.execute_reply": "2022-12-04T18:03:30.936394Z",
     "shell.execute_reply.started": "2022-12-04T18:03:30.918250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48434856, 0.57760195, 0.50681818, 0.63217737])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:03:33.035576Z",
     "iopub.status.busy": "2022-12-04T18:03:33.034504Z",
     "iopub.status.idle": "2022-12-04T18:03:33.055305Z",
     "shell.execute_reply": "2022-12-04T18:03:33.054106Z",
     "shell.execute_reply.started": "2022-12-04T18:03:33.035529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52438745, 0.51872096, 0.56815287, 0.54563297])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1: sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:07:21.999246Z",
     "iopub.status.busy": "2022-12-04T18:07:21.998546Z",
     "iopub.status.idle": "2022-12-04T18:09:45.981154Z",
     "shell.execute_reply": "2022-12-04T18:09:45.979909Z",
     "shell.execute_reply.started": "2022-12-04T18:07:21.999202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1299,  478,  327,  168],\n",
       "       [ 790, 1159,  265,  163],\n",
       "       [ 224,  168, 1533,  315],\n",
       "       [ 357,  148,  721, 1155]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probamos el modelo con los datos de validación\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "DATASET_VAL = '/kaggle/input/empathetic/ED_valid_p.csv'\n",
    "df_test = pd.read_csv(DATASET_VAL,sep=';')\n",
    "\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for index, row in df_test.iterrows(): \n",
    "    turno1 = row['utterance']\n",
    "    turno2 = row['utterance2']  \n",
    "    y_true.append(row['emotion'])\n",
    "    \n",
    "    emotion_pred = classifySentiment_loaded(turno1,turno2).item()\n",
    "    y_pred.append(emotion_pred)\n",
    "    \n",
    "# Creamos la matriz de confusión\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:10:07.929023Z",
     "iopub.status.busy": "2022-12-04T18:10:07.928317Z",
     "iopub.status.idle": "2022-12-04T18:10:08.184441Z",
     "shell.execute_reply": "2022-12-04T18:10:08.183466Z",
     "shell.execute_reply.started": "2022-12-04T18:10:07.928985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "matriz = confusion_matrix(y_true,y_pred)\n",
    "dataframe = pd.DataFrame(matriz)\n",
    "\n",
    "sns.heatmap(dataframe, annot=True,fmt=\".0f\", cbar=None, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\"), plt.tight_layout()\n",
    "plt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:10:15.744130Z",
     "iopub.status.busy": "2022-12-04T18:10:15.743761Z",
     "iopub.status.idle": "2022-12-04T18:10:15.757265Z",
     "shell.execute_reply": "2022-12-04T18:10:15.756095Z",
     "shell.execute_reply.started": "2022-12-04T18:10:15.744102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5551240560949299"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:10:47.823439Z",
     "iopub.status.busy": "2022-12-04T18:10:47.822404Z",
     "iopub.status.idle": "2022-12-04T18:10:47.844154Z",
     "shell.execute_reply": "2022-12-04T18:10:47.842987Z",
     "shell.execute_reply.started": "2022-12-04T18:10:47.823402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57174296, 0.4875894 , 0.684375  , 0.4850903 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:11:50.741318Z",
     "iopub.status.busy": "2022-12-04T18:11:50.740914Z",
     "iopub.status.idle": "2022-12-04T18:11:50.766706Z",
     "shell.execute_reply": "2022-12-04T18:11:50.765535Z",
     "shell.execute_reply.started": "2022-12-04T18:11:50.741285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48651685, 0.59344598, 0.53865074, 0.64131038])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T18:11:52.404149Z",
     "iopub.status.busy": "2022-12-04T18:11:52.403747Z",
     "iopub.status.idle": "2022-12-04T18:11:52.425561Z",
     "shell.execute_reply": "2022-12-04T18:11:52.424471Z",
     "shell.execute_reply.started": "2022-12-04T18:11:52.404118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5256981 , 0.53533487, 0.6028313 , 0.55236729])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1: sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-04T15:22:50.445063Z",
     "iopub.status.busy": "2022-12-04T15:22:50.444674Z",
     "iopub.status.idle": "2022-12-04T15:22:50.472087Z",
     "shell.execute_reply": "2022-12-04T15:22:50.471122Z",
     "shell.execute_reply.started": "2022-12-04T15:22:50.445030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nivel de emoción tensor([2], device='cuda:0')\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Probamos el modelo\n",
    "turno1 = \"My friend's boyfriend recently made a pass at me. I'm married, and I also am really good friend's with his girlfriend so I felt really bad. I made sure he knew I was loyal and honest to both!\"\n",
    "turno2 = 'Thats horrible. Did you tell on him?'\n",
    "\n",
    "emocion = classifySentiment_loaded(turno1,turno2).item()\n",
    "print(emocion)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNn93j1nBmhig81joS+aTIA",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
